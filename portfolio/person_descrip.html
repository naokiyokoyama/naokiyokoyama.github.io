<!DOCTYPE html>
<html >
  <head>
    <meta charset="UTF-8">

    <title>Naoki Yokoyama</title>

    <!--Favicon-->
    <link rel="icon" type="../image/png" href="../img/favicon.png">
    <!--CSS Links-->
    <link rel="stylesheet" href="../css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">    
    <link rel="stylesheet" href="../css/landing.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Heebo:light">
    <!--Scripts-->
    <script type="text/javascript" src="../js/analytics.js"></script>
    <script type="text/javascript" src="../js/jquery-2.1.3.min.js"></script>
  </head>

  <body>

    <div class="container">
      <div class="row">
        <div class="col-md-2"></div>
        <div class="col-md-8">

          <a class="title" href="../index.html">Naoki Yokoyama</a>
          <hr>
          <a href="../index.html#bio">About Me</a> &ensp;
          <a href="https://drive.google.com/file/d/1j0MELX5lTbUaxXdSLYF2bRDGz9wDlom2/view">CV</a> &ensp;
          <a href="../index.html#research">Research</a> &ensp;
          <a href="https://github.com/naokiyokoyama">GitHub</a> &ensp;
          <a href="https://scholar.google.com/citations?user=26MOv8wAAAAJ&hl=en">Google Scholar</a> &ensp;
          <br><br>
          <div class="panel-body">
              <div class="page-header">
                <center>
                  <h2>Pose Estimation and Person Description Using Convolutional Neural Networks</h2>
                </center>
              </div>
              <center>
                <img src="../img/robocup/robocup_ppl.jpg" alt="" width="80%">
                <br>
                <i class="fontsize">Predictions are made using OpenPose to detect humans and their body parts, which are then subjected to various deep convolutional classifiers.</i>
                <br>
              </center>
              <h3>OpenPose for Person Detection and Segmentation</h3>
              <p class="fontsize">
                OpenPose was used to find the keypoints (i.e. right elbow, left knee) of each person in the camera frame. Each person could then be segmented by their head, torso, and legs. Using three convolutional classifiers, their gender, age, and emotion could be inferred from their face. Using the DeepFashion dataset by the University of Hong Kong, I trained an InceptionV3 model to recognize the clothes in a picture. By feeding this model images of each person's torso and legs, their upper and lower clothes could be inferred. Finally, by using a color histogram conditioned on pixels near particular keypoints, the color of each clothing could also be inferred.  
              </p>
              <h3>DeepFashion Classifier</h3>
              <p class="fontsize">
                I trained an InceptionV3 as well as a YOLOv2 model on the <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html">DeepFashion dataset</a>. Ultimately, the InceptionV3 classifier was used, and was fed the upper and lower halves of each person detected by OpenPose.
              </p>
              <center>    
                <div class="video-responsive">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/7cvmcQJM0as" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div> 
                <p class="fontsize"><i>Demonstration of Person Description using the Toyota HSR.</i></p>
              </center>   
          </div>
          <div class="col-md-2"></div>
      </div>
    </div>  
    <script src="../js/bootstrap.js"></script>
  </body>
</html>