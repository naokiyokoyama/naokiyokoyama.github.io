<!DOCTYPE html>
<html >
  <head>
    <meta charset="UTF-8">

    <title>Naoki Yokoyama</title>

    <!--Favicon-->
    <link rel="icon" type="../image/png" href="img/favicon.png">
    <!--CSS Links-->
    <link rel="stylesheet" href="../css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">    
    <link rel="stylesheet" href="../css/landing.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Heebo:light">
    <!--Scripts-->
    <script type="text/javascript" src="../js/analytics.js"></script>
    <script type="text/javascript" src="../js/jquery-2.1.3.min.js"></script>
  </head>

  <body>

    <div class="container">
      <div class="row">
        <div class="col-md-2"></div>
        <div class="col-md-8">

          <a class="title" href="../index.html">Naoki Yokoyama</a>
          <hr>
          <a href="../index.html#bio-anchor">About Me</a> &ensp;
          <a href="../index.html#research-anchor">Research</a> &ensp;
          <a href="../index.html#tutorial-anchor">Tutorials</a> &ensp;
         <!--  <a href="../index.html#side-anchor">Side Projects</a> &ensp; -->
<!--           <a href="#side-anchor">Press Coverage</span> &ensp; -->
          <a href="https://drive.google.com/file/d/1j0MELX5lTbUaxXdSLYF2bRDGz9wDlom2/view">CV</a> &ensp;
          <br><br>
					<div class="panel-body">
						<div class="page-header">
							<center>
								<h2>Autoencoders (Code Coming Soon!)</h2>
							</center>
						</div>
						<h3>An Unsupervised Generative Model</h3>
							<center>
								<img src="../img/dlt_icons/ae.png" width="80%">
							</center>
						<p class="fontsize">
							<li class="fontsize">One of the most simple neural nets that serves as a generator, as opposed to a discriminator.</li>
							<li class="fontsize">Encodes its input to a smaller dimension, then decodes that compressed representation to <b style="color: red">try to reconstruct the input.</b></li>
							<li class="fontsize">Since the goal is to simply reconstruct the input, the training can be unsupervised, as the net already has the input to compare against the output.</li>
						</p>

						<h3>Why reconstruct the input?</h3>
						<p class="fontsize">
							<li class="fontsize">After training, the net will presumably have learned how to extract the important features of the input, and use them to recreate a convincing reconstruction.</li>
							<li class="fontsize">Thus, if we pass a noisy input, the autoencoder should be able to accurately recreate the original input.</li>
							<li class="fontsize">To make the autencoder more robust against certain types of noise, the noise could be added to the training samples before being passed through the net, but the output would still be compared against the original, noise-free input.</li>
						</p>

						<h3>Noise Removal and Beyond</h3>
						<center>
							<img src="../img/dlt/ae/facecompletion.png" width="80%">
							<p class="fontsize"><i>Face completion using an AE (within a GAN) ["Generative Adversarial Denoising Autoencoder for Face Completion"]</i></p>
							<img src="../img/dlt/ae/neural_inpainting.jpg" width="80%">
							<p class="fontsize"><i>Semantic inpainting on masked images ["Context Encoders: Feature Learning by Inpainting" Pathak et al. CVPR 2016]</i></p>
							<img src="../img/dlt/ae/cage.gif" width="80%">
							<p class="fontsize"><i>Two autoencoders used for swapping faces between two people (actress' face replaced by Nicholas Cage's) (aka DeepFakes)</i></p>
						</center>
					</div>
          <div class="col-md-2"></div>
      </div>
    </div>  
    <script src="../js/bootstrap.js"></script>
  </body>
</html>