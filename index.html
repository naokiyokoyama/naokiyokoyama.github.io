<!DOCTYPE html>
<html >
  <head>
    <meta charset="UTF-8">

    <title>Naoki Yokoyama</title>

    <!--Favicon-->
    <link rel="icon" type="../image/png" href="img/favicon.png">
    <!--CSS Links-->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">    
    <link rel="stylesheet" href="css/landing.css">    
    <!--Scripts-->
    <script type="text/javascript" src="js/analytics.js"></script>
    <script type="text/javascript" src="js/jquery-2.1.3.min.js"></script>

  </head>

  <body>

    <div class="container">
      <div class="row">
        <div class="col-md-1"></div>
        <div class="col-md-10">

          <a class="title" href="index.html">Naoki Yokoyama</a>
          <hr>
          <a href="#bio">About Me</a> &ensp;
          <a href="https://drive.google.com/file/d/1j0MELX5lTbUaxXdSLYF2bRDGz9wDlom2/view">CV</a> &ensp;
          <a href="#research">Research</a> &ensp;
          <a href="https://github.com/naokiyokoyama">GitHub</a> &ensp;
          <a href="https://scholar.google.com/citations?user=26MOv8wAAAAJ&hl=en">Google Scholar</a> &ensp;
          <!-- <a href="#side">Side Projects</a> &ensp; -->
<!--           <a href="#side">Press Coverage</span> &ensp; -->
          <br><br>

          <div class="row">
            <div class="col-md-5">
              <center>
                <div class="hidden-xs hidden-sm">
                  <img src="img/me.JPG" class="featuredimg" width="100%">
                </div>
                <div class="visible-xs visible-sm">
                  <img src="img/me.JPG" class="featuredimg" width="70%">
                  <br><br>
                </div>
              </center> 
            </div>
            <div class="col-md-7">
              <p>
                Ph.D. Candidate in Robotics at Georgia Tech<br>
                Atlanta, GA<br>
                <br>
                Northeastern University <br>
                B.S. and M.S. Electrical Engineering <br>
                Concn. in Machine Learning & Computer Vision
              </p>
            </div>
          </div>

          <br>
          <hr>
          <h1 class="anchor" id="bio"> </h1>
          <h2>About Me</h2>
          <p>
            I am currently a Robotics Ph.D. student at Georgia Tech advised by <a class=body-size href="https://www.cc.gatech.edu/~dbatra/"><u>Dhruv Batra</u></a> and <a class=body-size href="https://www.cc.gatech.edu/~sha9/"><u>Sehoon Ha</u></a>. Previously, I graduated with my BS and MS from Northeastern University. My research interests involve scalable learning methods that will teach robots to effectively perceive and interact within various environments in the real world by training them within realistic simulators before transferring the learned skills to reality. 
            <br><br>
            I am currently interning at Amazon, and previous interned at Meta AI with <a class=body-size href="https://scholar.google.com/citations?user=H8FJlJoAAAAJ&hl=en"><u>Akshara Rai</u></a> on mobile manipulation for object rearrangement. 
            <br><br>
            Previously I also worked with <a class=body-size href="https://coe.northeastern.edu/people/padir-taskin/"><u>Taskin Padir</u></a> in the Robotics and Intelligent Vehicles Research (RIVeR) lab at Northeastern University. There, I led Team Northeastern in mutiple international robotics competitions such as the 2019 RoboCup@Home competition in Sydney, Australia, the 2018 World Robot Summit in Tokyo, Japan, and the Robocup@Home 2018 in Montreal, Canada, where we placed 4th internationally and 1st in the USA. 
            <br><br>
            I have also had the pleasure of mentoring other students, such as <a class=body-size href="https://qianluo.netlify.app/"><u>Qian Luo</u></a> (MS@GT), <a class=body-size href="https://www.simarkareer.com/"><u>Simar Kareer</u></a> (MS@GT), and <a class=body-size href="https://www.linkedin.com/in/marco-delgado--/"><u>Marco Delgado</u></a> (BS@GT) in research projects.
            <br>
            <div class="row" align="center">
              <div class="col-xs-4" align="center">
                  <div class='logo'>
                    <img height='40px' padding-bottom=30px src="img/logos/river.png">
                  </div>
                  <br>
                  <div>
                      <span class="descrip"> RIVeR Research Lab <br> 2017 - 2019 </span>
                  </div>
              </div>
              <div class="col-xs-4" align="center">
                  <div class='logo'>
                    <img height='40px' padding-bottom=30px src="img/logos/fair.png">
                  </div>
                  <br>
                  <div>
                      <span class="descrip"> Facebook AI Research <br> Summer 2021 </span>
                  </div>
              </div>
            </div>
          </p>
          <br>
          <hr>
          <h1 class="anchor" id="research"> </h1>
          <h2>Research</h2>
          <br>
          <!--- OIAYN -->
          <div class="row">
            <div class="col-sm-6">
              <center>
                <img src="img/oiayn/oiayn_figure.png" width=100%>
                <br>
                <br>
                <video playsinline autoplay muted loop style="width: 100%" class="webby">
                  <source src="https://github.com/naokiyokoyama/website_media/raw/master/20.0x_mf_desk2bathroom_run3.mp4" type="video/mp4"></source>
                </video>
              </center>
            </div>
            <div class="col-sm-6">
                <span class="subhead">Is Mapping Necessary for Realistic PointGoal Navigation?</span>
                <br>  
                <p>
                  <i>
                    Ruslan Partsey, Erik Wijmans, <strong>Naoki Yokoyama</strong>, Oles Dobosevych, Dhruv Batra, Oleksandr Maksymets
                    <br><br>
                    Conference on Computer Vision and Pattern Recognition (CVPR) 2022
                  </i>
                </p>
                <a class="proj" href="https://rpartsey.github.io/pointgoalnav/">Project Page</a>
                <!-- <a class="proj" href="https://arxiv.org/abs/XXXXX">arXiv link</a> -->
                <br><br>
                <p>Can an autonomous agent navigate in a new environment without ever building an explicit map?</p>
            </div>
          </div>
          <hr>
          <!--- iGibson Challenge -->
          <div class="row">
            <div class="col-sm-6">
              <center>
                <video playsinline autoplay muted loop style="width: 100%" class="webby">
                  <source src="https://github.com/naokiyokoyama/website_media/raw/master/social_nav_example.mp4" type="video/mp4"></source>
                </video>
                <a href="https://www.youtube.com/watch?v=kC9wdC3abDo">
                  <img src="https://raw.githubusercontent.com/naokiyokoyama/website_media/master/imgs/igibson2021/igibson_small.jpg" alt="" width=60%>
                </a>
              </center>
            </div>
            <div class="col-sm-6">
                <span class="subhead">Benchmarking Augmentation Methods for Learning Robust Navigation Agents: the Winning Entry of the 2021 iGibson Challenge</span>
                <br>
                <p>
                  <i>
                    <strong>Naoki Yokoyama</strong>, Qian Luo, Dhruv Batra, Sehoon Ha
                    <br><br>
                    Embodied AI Workshop at Conference on Computer Vision and Pattern Recognition (CVPR) 2021
                  </i>
                </p>
                <a class="proj" href="http://svl.stanford.edu/igibson/challenge.html">Challenge Page</a>
                <a class="proj" href="https://embodied-ai.org/">Workshop Page</a>
                <a class="proj" href="https://arxiv.org/abs/2109.10493">arXiv link</a>
                <br><br>
                <p><i>1st place in Interactive Navigation, 5th in Social Navigation.</i></p>
            </div>
          </div>
          <hr>
          <!--- SCT -->
          <div class="row">
            <div class="col-sm-6">
                <video playsinline autoplay muted loop style="width: 100%" class="webby">
                  <source src="https://github.com/naokiyokoyama/website_media/raw/master/sct_reality.mp4" type="video/mp4"></source>
                </video>
            </div>
            <div class="col-sm-6">
                <span class="subhead">Success Weighted By Completion Time: A Dynamics-Aware Evaluation Criteria for Embodied Navigation</span>
                <br>
                <p>
                  <i><strong>Naoki Yokoyama,</strong> Sehoon Ha, Dhruv Batra</i>
                  <br><br>
                  <i>International Conference on Intelligent Robots and Systems (IROS) 2021</i>
                </p>
                <br>
                <a class="proj" href="portfolio/sct.html">Project Page</a>
                <a class="proj" href="https://www.youtube.com/watch?v=QOQ56XVIYVE">YouTube</a>
                <a class="proj" href="https://arxiv.org/abs/2103.08022">arXiv link</a>
                <a class="proj" href="https://github.com/naokiyokoyama/rrt_star">Code</a>
                <br><br>
                <p>Dynamics-aware training and evaluation for navigation. Demonstrated that trained agents better leveraged the dynamics of the robot to be faster than previous work, both within simulation and in the real world.</p>
                <br>
            </div>
          </div>
          <hr>
          <!--- Sydney -->
          <div class="row">
            <div class="col-sm-6">
                <img src="img/portfolio_icons/robocup2019.jpg" width="100%">
            </div>
            <div class="col-sm-6">
                <span class="subhead">Robocup@Home 2019 in Sydney, Australia</span>
                <br><br>
                <a class="proj" href="https://www.youtube.com/watch?v=MaeMwiMN7QU">YouTube</a>
                <br><br>
                <p>Finished 1st place among US teams.</p>
            </div>
          </div>
          <hr>
          <!--- WRS -->
          <div class="row">
            <div class="col-sm-6">
                <video playsinline autoplay muted loop style="width: 100%" class="webby">
                  <source src="https://github.com/naokiyokoyama/website_media/raw/master/wrs_clip.mp4" type="video/mp4"></source>
                </video>
            </div>
            <div class="col-sm-6">
                <span class="subhead">World Robot Competition 2018 in Tokyo, Japan</span>
                <br>
                <br>
                <p>Competition with mobile manipulation and perception tasks, held in Odaiba's Tokyo Big Sight.</p>
            </div>
          </div>
          <hr>
          <!--- Montreal -->
          <div class="row">
            <div class="col-sm-6">
              <center>
                <img src="img/portfolio_icons/robocup2018.jpg" width="100%">
                <br><br>
                <video playsinline autoplay muted loop style="width: 100%" class="webby">
                  <source src="https://github.com/naokiyokoyama/website_media/raw/master/mask_rcnn_robust_detections.mp4" type="video/mp4"></source>
                </video>
              </center>
            </div>
            <div class="col-sm-6">
              <span class="subhead">Robocup@Home 2018 in Montreal, Canada</span>
              <br><br>
              <a class="proj" href="portfolio/maskrcnn.html">Object Segmentation</a>
              <a class="proj" href="portfolio/person_descrip.html">Person Description</a>
              <br><br>
              <p>Finished 4th internationally, 1st among USA. Completed various mobile manipulation and human-robot interaction tasks using deep learning and computer vision.</p>
            </div>
          </div>
          <hr>
          
        </div>
        <div class="col-md-1"></div>
      </div>
    </div>  
    <script src="js/bootstrap.js"></script>
  </body>
</html>
